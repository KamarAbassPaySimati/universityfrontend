trigger:
  branches:
    include:
      - qa
      - pre-production
      - master
pr:
  branches:
    include:
      - qa
variables:
  - group: general
  - ${{ if eq(variables['Build.SourceBranch'], 'refs/heads/master') }}:
    - group: master
  - ${{ if eq(variables['Build.SourceBranch'], 'refs/heads/qa') }}:
    - group: qa
  - ${{ if eq(variables['Build.SourceBranch'], 'refs/heads/pre-production') }}:
    - group: pre-production
  - ${{ if or(contains(variables['build.SourceBranch'], 'feature'), contains(variables['build.SourceBranch'], 'bugfix'), contains(variables['build.SourceBranch'], 'hotfix')) }}:
    - group: develop


stages:
- stage: CodeQuality
  jobs:
    - job: "lint"
      displayName: "Code Quality"
      condition: and(or(contains(variables['build.SourceBranch'], 'feature'), contains(variables['build.SourceBranch'], 'bugfix'), contains(variables['build.SourceBranch'], 'hotfix')), succeeded())
      pool:
          vmImage: "ubuntu-latest"
      steps:
        - task: Cache@2
          inputs:
            key: 'npmV2 | "$(Agent.OS)" | package.json'
            restoreKeys: |
              npm | "$(Agent.OS)"
            path: "$(System.DefaultWorkingDirectory)/node_modules"
            cacheHitVar: CACHE_RESTORED
          displayName: Cache npm
        - script: |
            npm install --cache .npm
            node licence_complaiance.js
            export AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID_MAIN}
            export AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY_MAIN}
            aws s3 sync licenses.json s3://$S3_BUCKET_LIVING_DOCUMENTATION/living-documentation-ADMIN/dev/licenses.json
          condition: ne(variables.CACHE_RESTORED, 'true')
          displayName: 'Dependencies'
        - script: |
            npm run eslint
          displayName: 'Lint'
    - job: "secret"
      displayName: "Secret Checking"
      condition: and(or(contains(variables['build.SourceBranch'], 'feature'), contains(variables['build.SourceBranch'], 'bugfix'), contains(variables['build.SourceBranch'], 'hotfix')), succeeded())
      pool:
          vmImage: "ubuntu-latest"
      steps:
        - script: |
            pip3 install detect-secrets
            detect-secrets scan
          displayName: 'Lint'
    - job: "licence_complaiance"
      displayName: "License Compliance"
      condition: and(or(contains(variables['build.SourceBranch'], 'feature'), contains(variables['build.SourceBranch'], 'bugfix'), contains(variables['build.SourceBranch'], 'hotfix')), succeeded())
      pool:
          vmImage: "ubuntu-latest"
      steps:
        - script: |
            npm install -g license-checker 
            license-checker --json > licenses.json  
            node scripts/license.js
          displayName: 'License Compliance'
    - job: "sast"
      displayName: 'Static Application Security Testing (SAST)'
      condition: and(or(contains(variables['build.SourceBranch'], 'feature'), contains(variables['build.SourceBranch'], 'bugfix'), contains(variables['build.SourceBranch'], 'hotfix')), succeeded())
      pool:
          vmImage: "ubuntu-latest"
      steps:
        - script: |
            pip3 install njsscan
            njsscan -w .
          displayName: 'Static Application Security Testing (SAST)'
    # - job: "dast"
    #   displayName: 'Dynamic Application Security Testing (DAST)'
    #   dependsOn: Download_Environment
    #   condition: and(or(contains(variables['build.SourceBranch'], 'feature'), contains(variables['build.SourceBranch'], 'bugfix'), contains(variables['build.SourceBranch'], 'hotfix')), succeeded())
    #   pool:
    #       vmImage: "ubuntu-latest"
    #   steps:
    #     - script: |
    #         echo "test"
    #         # pip install --upgrade mobsfscan
    #         # mobsfscan -w app/src --config scripts/.mobsf
    #       displayName: 'Dynamic Application Security Testing (DAST)'
- stage: Build
  jobs:
    - job: "Download_Environment"
      displayName: "Dependencies"
      pool:
        vmImage: "ubuntu-latest"
      steps:
        - script: |
            sudo pip3 install --upgrade pip
            pip3 install awscli --upgrade --user
            export PATH="/home/vsts/.local/bin:$PATH"
            sh scripts/azure_envs.sh
          displayName: 'Copy Environment Files'
        - publish: $(System.DefaultWorkingDirectory)/.env
          artifact: Environment
    - job: build
      displayName: "Build"
      dependsOn: Download_Environment
      pool:
        vmImage: "ubuntu-latest"
      steps:
        - task: DownloadPipelineArtifact@2
          name: environment
          inputs:
            artifact: Environment
            targetPath: '$(System.DefaultWorkingDirectory)'
        - task: Cache@2
          inputs:
            key: 'npmV2 | "$(Agent.OS)" | package.json'
            restoreKeys: |
              npm | "$(Agent.OS)"
            path: "$(System.DefaultWorkingDirectory)/node_modules"
            cacheHitVar: CACHE_RESTORED
          displayName: Cache npm
        - script: |
            npm install --cache .npm
          condition: ne(variables.CACHE_RESTORED, 'true')
          displayName: 'Dependencies'
        - script: |
            npm run build
            mkdir artifact
            mv dist artifact
          displayName: 'Build'
        - publish: $(System.DefaultWorkingDirectory)/artifact
          artifact: bundle
- stage: Test
  jobs:
    - job: UnitTesting
      displayName: "Unit Testing"
      condition: and(or(contains(variables['build.SourceBranch'], 'feature'), contains(variables['build.SourceBranch'], 'bugfix'), contains(variables['build.SourceBranch'], 'hotfix')), succeeded())
      pool:
        vmImage: "ubuntu-latest"
      steps:
        - task: Cache@2
          inputs:
            key: 'npmV2 | "$(Agent.OS)" | package.json'
            restoreKeys: |
              npm | "$(Agent.OS)"
            path: "$(System.DefaultWorkingDirectory)/node_modules"
            cacheHitVar: CACHE_RESTORED
          displayName: Cache npm
        - script: |
            npm install --cache .npm
          condition: ne(variables.CACHE_RESTORED, 'true')
        - task: DownloadPipelineArtifact@2
          name: environment
          inputs:
            artifact: Environment
            targetPath: '$(System.DefaultWorkingDirectory)'
        - task: DownloadPipelineArtifact@2
          name: bundle
          inputs:
            artifact: bundle
            targetPath: '$(System.DefaultWorkingDirectory)'
        - script: |
            npm install pm2 -g
            source .env
            npm run build
            npm install express --force
            pm2 start scripts/server.js
            sleep 5
            mkdir reports
            npm install nyc --save-dev --force
            node scripts/bdd_unit_testing_azure.js
          displayName: Unit Testing
        - publish: $(System.DefaultWorkingDirectory)/reports # Assuming logs are in working directory
          artifact: reports
          condition: always()
        - publish: $(System.DefaultWorkingDirectory)/test/step-definations/coverageData/ # Assuming logs are in working directory
          artifact: coverage
          condition: always()
        - publish: $(System.DefaultWorkingDirectory)/test/step-definations/failedScenarios/ # Assuming logs are in working directory
          artifact: failedScenarios
          condition: always()
    - job: UnitTestingResult
      variables:
        myVariable: $[replace(variables['BUILD.SOURCEBRANCH'], 'refs/heads/', '')]
      displayName: "Unit Testing Result"
      condition: or(contains(variables['build.SourceBranch'], 'feature'), contains(variables['build.SourceBranch'], 'bugfix'), contains(variables['build.SourceBranch'], 'hotfix'))
      dependsOn: UnitTesting
      pool:
        vmImage: "ubuntu-latest"
      steps:
      - task: Cache@2
        inputs:
          key: 'npmV2 | "$(Agent.OS)" | package.json'
          restoreKeys: |
            npm | "$(Agent.OS)"
          path: "$(System.DefaultWorkingDirectory)/node_modules"
          cacheHitVar: CACHE_RESTORED
        displayName: Cache npm
      - script: |
          npm install --cache .npm
        condition: ne(variables.CACHE_RESTORED, 'true')
      - script: |
         mkdir reports
         mkdir test/step-definations/coverageData/
      - task: DownloadPipelineArtifact@2
        name: reports
        inputs:
          artifact: reports
          targetPath: '$(System.DefaultWorkingDirectory)/reports'
      - task: DownloadPipelineArtifact@2
        name: coverage
        inputs:
          artifact: coverage
          targetPath: '$(System.DefaultWorkingDirectory)/test/step-definations/coverageData/'
      - script: |
          echo "##vso[task.setvariable variable=RepositoryName]$BUILD_REPOSITORY_NAME"
          echo "##vso[task.setvariable variable=SourceBranch]$SourceBranch"
          source .env
          mkdir coverage
          npm install nyc --save-dev --force
          npm run generate_report
          node scripts/livingdoc_azure.js $BUILD_REPOSITORY_NAME
          export AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID_MAIN}
          export AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY_MAIN}
          aws s3 sync living-documentation s3://$S3_BUCKET_LIVING_DOCUMENTATION/living-documentation-ADMIN/dev/
          aws s3 sync coverage s3://$S3_BUCKET_LIVING_DOCUMENTATION/coverage-ADMIN/dev/
        displayName: 'BDD Living documentation'
    - job: IntegrationTesting
      displayName: "Integration Testing"
      condition: and(succeeded(), contains(variables['build.SourceBranch'], 'qa'))
      pool:
        vmImage: "ubuntu-latest"
      steps:
        - task: DownloadPipelineArtifact@2
          name: environment
          inputs:
            artifact: Environment
            targetPath: '$(System.DefaultWorkingDirectory)'
        - task: DownloadPipelineArtifact@2
          name: bundle
          inputs:
            artifact: bundle
            targetPath: '$(System.DefaultWorkingDirectory)'
        - script: |
            npm install pm2 -g
            source .env
            npm install express --force
            pm2 start scripts/server.js
            sleep 60
            mkdir reports
            npm install nyc --save-dev --force
            node scripts/bdd-execution-split1.js
    - job: BrowserPerformanceTesting
      displayName: "Browser Performance Testing"
      condition: and(or(contains(variables['build.SourceBranch'], 'feature'), contains(variables['build.SourceBranch'], 'bugfix'), contains(variables['build.SourceBranch'], 'hotfix'), contains(variables['build.SourceBranch'], 'qa')), succeeded())
      pool:
        vmImage: "ubuntu-latest"
      steps:
        - task: Cache@2
          inputs:
            key: 'npmV2 | "$(Agent.OS)" | package.json'
            restoreKeys: |
              npm | "$(Agent.OS)"
            path: "$(System.DefaultWorkingDirectory)/node_modules"
            cacheHitVar: CACHE_RESTORED
          displayName: Cache npm
        - script: |
            npm install --cache .npm
          condition: ne(variables.CACHE_RESTORED, 'true')
        - task: DownloadPipelineArtifact@2
          name: environment
          inputs:
            artifact: Environment
            targetPath: '$(System.DefaultWorkingDirectory)'
        - task: DownloadPipelineArtifact@2
          name: bundle
          inputs:
            artifact: bundle
            targetPath: '$(System.DefaultWorkingDirectory)'
        - script: |
            source .env
            npm run build
            npm install express --force
            npm install pm2 sitespeed.io -g
            pm2 start scripts/sitespeed-server.js
            sleep 30
            sitespeed.io  --multi scripts/sitespeed/testMultipleURLs.js --preScript scripts/sitespeed/login.js --budget.configPath scripts/budget.json -n 1 --firstParty ".amazon.com" --firstParty "sdk.relicx.ai" --headless true --browsertime.chrome.args no-sandbox
          displayName: BrowserPerformance
        - publish: $(System.DefaultWorkingDirectory)/sitespeed-result # Assuming logs are in working directory
          artifact: sitespeed-result
          condition: always()
     
- stage: Deploy
  jobs:
    - job: deployment
      displayName: "Deployment"
      condition: succeeded()
      pool:
        vmImage: "macOS-13"
      steps:
        - task: DownloadPipelineArtifact@2
          name: bundle
          inputs:
            artifact: bundle
            targetPath: '$(System.DefaultWorkingDirectory)'
        - task: DownloadPipelineArtifact@2
          name: environment
          inputs:
            artifact: environment
            targetPath: '$(System.DefaultWorkingDirectory)'
        - script: |
            source .env
            ls -R
            aws s3 sync dist s3://$ADMIN_S3_BUCKET
            aws cloudfront create-invalidation --distribution-id $ADMIN_DISTRIBUTION_ID --paths "/*"
          displayName: 'Deployment'
    - job: DAST
      displayName: "Dynamic Application Security Testing (DAST)"
      condition: and(or(contains(variables['build.SourceBranch'], 'feature'), contains(variables['build.SourceBranch'], 'bugfix'), contains(variables['build.SourceBranch'], 'hotfix'), contains(variables['build.SourceBranch'], 'qa')), succeeded())
      pool:
        vmImage: "ubuntu-latest"
      steps:
        - task: Cache@2
          inputs:
            key: 'npmV2 | "$(Agent.OS)" | package.json'
            restoreKeys: |
              npm | "$(Agent.OS)"
            path: "$(System.DefaultWorkingDirectory)/node_modules"
            cacheHitVar: CACHE_RESTORED
          displayName: Cache npm
        - script: |
            npm install --cache .npm
          condition: ne(variables.CACHE_RESTORED, 'true')
        - task: DownloadPipelineArtifact@2
          name: environment
          inputs:
            artifact: Environment
            targetPath: '$(System.DefaultWorkingDirectory)'
        - task: DownloadPipelineArtifact@2
          name: bundle
          inputs:
            artifact: bundle
            targetPath: '$(System.DefaultWorkingDirectory)'
        - script: |
            npm install pm2 -g
            source .env
            npm run build
            npm install express --force
            pm2 start scripts/server.js
            docker run -u zap -p 8080:8080 -d softwaresecurityproject/zap-stable zap.sh -daemon -host 0.0.0.0 -port 8080 -config api.disablekey=true -config api.addrs.addr.name=.* -config api.addrs.addr.regex=true
            sleep 30
            mkdir test_results
            pip install beautifulsoup4
            python scripts/dast.py
          displayName: Unit Testing
        - publish: $(System.DefaultWorkingDirectory)/repotest_resultsrts # Assuming logs are in working directory
          artifact: dast_test_results
          condition: always()
    
    