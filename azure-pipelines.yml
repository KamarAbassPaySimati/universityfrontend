trigger:
  branches:
    include:
      - qa
      - pre-prod
      - master
pr:
  branches:
    include:
      - qa
      - pre-prod
variables:
  - group: general
  - ${{ if eq(variables['Build.SourceBranch'], 'refs/heads/master') }}:
    - group: master
  - ${{ if eq(variables['Build.SourceBranch'], 'refs/heads/qa') }}:
    - group: qa
  - ${{ if eq(variables['Build.SourceBranch'], 'refs/heads/pre-prod') }}:
    - group: pre-production
  - ${{ if eq(variables['Build.Reason'], 'PullRequest') }}:
    - group: develop


stages:
- stage: CodeQuality
  jobs:
    # - job: "pr_review"
    #   displayName: "GPT Pull Request Review"
    #   condition: and(or(contains(variables['System.PullRequest.SourceBranch'], 'feature'), contains(variables['System.PullRequest.SourceBranch'], 'bugfix'), contains(variables['System.PullRequest.SourceBranch'], 'ci'), contains(variables['System.PullRequest.SourceBranch'], 'hotfix')), succeeded())
    #   pool:
    #       vmImage: "ubuntu-latest"
    #   steps:
    #     - checkout: self
    #       persistCredentials: true
    #     - task: GPTPullRequestReview@0
    #       inputs:
    #         api_key: $(OPENAI_TOKEN)
    #         aoi_endpoint: $(AOI_ENDPOINT)
    - job: "lint"
      displayName: "Code Quality"
      # condition: and(succeeded(), contains(variables['build.SourceBranch'], 'qa'))
      condition: and(or(contains(variables['System.PullRequest.SourceBranch'], 'feature'), contains(variables['System.PullRequest.SourceBranch'], 'bugfix'), contains(variables['System.PullRequest.SourceBranch'], 'ci'), contains(variables['System.PullRequest.SourceBranch'], 'hotfix')), succeeded())
      pool:
          vmImage: "ubuntu-latest"
      steps:
        - task: Cache@2
          inputs:
            key: 'npmV3 | "$(Agent.OS)" | package.json'
            restoreKeys: |
              npm | "$(Agent.OS)"
            path: "$(System.DefaultWorkingDirectory)/node_modules"
            cacheHitVar: CACHE_RESTORED
          displayName: Cache npm
        - script: |
            npm install --force
            node scripts/licences_complaince.js
            export AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID_MAIN}
            export AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY_MAIN}
            aws s3 cp licenses.json s3://$S3_BUCKET_LIVING_DOCUMENTATION/licences-ADMIN/dev/licenses.json
          condition: ne(variables.CACHE_RESTORED, 'true')
          displayName: 'Dependencies'
        - script: |
            npm run eslint
          displayName: 'Lint'
    - job: "secret"
      displayName: "Secret Checking"
      # condition: and(succeeded(), contains(variables['build.SourceBranch'], 'qa'))
      condition: and(or(contains(variables['System.PullRequest.SourceBranch'], 'feature'), contains(variables['System.PullRequest.SourceBranch'], 'bugfix'), contains(variables['System.PullRequest.SourceBranch'], 'ci'), contains(variables['System.PullRequest.SourceBranch'], 'hotfix')), succeeded())
      pool:
          vmImage: "ubuntu-latest"
      steps:
        - script: |
            pip3 install detect-secrets
            detect-secrets scan
          displayName: 'Lint'
    - job: "licence_complaiance"
      displayName: "License Compliance"
      # condition: and(succeeded(), contains(variables['build.SourceBranch'], 'qa'))
      condition: and(or(contains(variables['System.PullRequest.SourceBranch'], 'feature'), contains(variables['System.PullRequest.SourceBranch'], 'bugfix'), contains(variables['System.PullRequest.SourceBranch'], 'ci'), contains(variables['System.PullRequest.SourceBranch'], 'hotfix')), succeeded())
      pool:
          vmImage: "ubuntu-latest"
      steps:
        - script: |
            npm install -g license-checker 
            license-checker --json > licenses.json  
            node scripts/license.js
          displayName: 'License Compliance'
    - job: "sast"
      displayName: 'Static Application Security Testing (SAST)'
      # condition: and(succeeded(), contains(variables['build.SourceBranch'], 'qa'))
      condition: and(or(contains(variables['System.PullRequest.SourceBranch'], 'feature'), contains(variables['System.PullRequest.SourceBranch'], 'bugfix'), contains(variables['System.PullRequest.SourceBranch'], 'ci'), contains(variables['System.PullRequest.SourceBranch'], 'hotfix')), succeeded())
      pool:
          vmImage: "ubuntu-latest"
      steps:
        - script: |
            pip3 install njsscan
            njsscan -w .
          displayName: 'Static Application Security Testing (SAST)'

- stage: Build
  jobs:
    - job: "Download_Environment"
      displayName: "Dependencies"
      pool:
        vmImage: "ubuntu-latest"
      steps:
        - script: |
            aws sts get-caller-identity
            ./scripts/azure_envs.sh
          displayName: 'Copy Environment Files'
        - publish: $(System.DefaultWorkingDirectory)/.env
          artifact: Environment
    - job: build
      displayName: "Build"
      dependsOn: Download_Environment
      pool:
        vmImage: "ubuntu-latest"
      steps:
        - task: DownloadPipelineArtifact@2
          name: environment
          inputs:
            artifact: Environment
            targetPath: '$(System.DefaultWorkingDirectory)'
        - task: Cache@2
          inputs:
            key: 'npmV3 | "$(Agent.OS)" | package.json'
            restoreKeys: |
              npm | "$(Agent.OS)"
            path: "$(System.DefaultWorkingDirectory)/node_modules"
            cacheHitVar: CACHE_RESTORED
          displayName: Cache npm
        - script: |
            npm install --force
          condition: ne(variables.CACHE_RESTORED, 'true')
          displayName: 'Dependencies'
        - script: |
            export NODE_OPTIONS=--max-old-space-size=8192
            npm run build
            mkdir artifact
            mv dist artifact
          displayName: 'Build'
        - publish: $(System.DefaultWorkingDirectory)/artifact
          artifact: bundle

- stage: Test
  jobs:
    - job: BrowserPerformanceTesting
      displayName: "Browser Performance Testing"
      condition: and(or(contains(variables['System.PullRequest.SourceBranch'], 'feature'), contains(variables['System.PullRequest.SourceBranch'], 'bugfix'), contains(variables['System.PullRequest.SourceBranch'], 'ci'), contains(variables['System.PullRequest.SourceBranch'], 'hotfix')), succeeded())
      pool:
        vmImage: "ubuntu-latest"
      steps:
        - task: Cache@2
          inputs:
            key: 'npmV3 | "$(Agent.OS)" | package.json'
            restoreKeys: |
              npm | "$(Agent.OS)"
            path: "$(System.DefaultWorkingDirectory)/node_modules"
            cacheHitVar: CACHE_RESTORED
          displayName: Cache npm
        - script: |
            npm install --force
          condition: ne(variables.CACHE_RESTORED, 'true')
        - task: DownloadPipelineArtifact@2
          name: environment
          inputs:
            artifact: Environment
            targetPath: '$(System.DefaultWorkingDirectory)'
        - task: DownloadPipelineArtifact@2
          name: bundle
          inputs:
            artifact: bundle
            targetPath: '$(System.DefaultWorkingDirectory)'
        - script: |
            source .env
            npm install express --force
            npm install pm2 sitespeed.io -g
            pm2 start scripts/sitespeed-server.js
            sleep 30
            sitespeed.io  --multi scripts/sitespeed/testMultipleURLs.js --preScript scripts/sitespeed/login.js --budget.configPath scripts/budget.json -n 1 --firstParty ".amazon.com" --firstParty "sdk.relicx.ai" --headless true --browsertime.chrome.args no-sandbox
          displayName: BrowserPerformance
        - publish: $(System.DefaultWorkingDirectory)/sitespeed-result # Assuming logs are in working directory
          artifact: sitespeed-result
          condition: always()
     
- stage: Deploy
  jobs:
    - deployment: Deployment
      condition: and(or(contains(variables['Build.Reason'], 'PullRequest'),contains(variables['build.SourceBranch'], 'master'), contains(variables['build.SourceBranch'], 'qa'), contains(variables['build.SourceBranch'], 'pre-prod')), succeeded())
      displayName: Deployment
      pool:
        vmImage: 'macos-latest'
      ${{ if eq(variables['Build.SourceBranchName'], 'master') }}:
          environment: 'Production'
      ${{ elseif eq(variables['Build.SourceBranchName'], 'pre-prod') }}:
          environment: 'Pre-Production'
      ${{ elseif eq(variables['Build.SourceBranchName'], 'qa') }}:
          environment: 'Testing'
      ${{ else }}:
          environment: 'Development'
      strategy:
        # Default deployment strategy, more coming...
        runOnce:
          deploy:
            steps:
              - task: DownloadPipelineArtifact@2
                name: bundle
                inputs:
                  artifact: bundle
                  targetPath: '$(System.DefaultWorkingDirectory)'
              - task: DownloadPipelineArtifact@2
                name: environment
                inputs:
                  artifact: Environment
                  targetPath: '$(System.DefaultWorkingDirectory)'
              - script: |
                  source .env
                  aws s3 sync dist s3://$ADMIN_S3_BUCKET --acl public-read
                  aws cloudfront create-invalidation --distribution-id $ADMIN_DISTRIBUTION_ID --paths "/*" 
                displayName: 'Deployment'
                
    - job: DAST
      displayName: "Dynamic Application Security Testing (DAST)"
      condition: and(or(contains(variables['System.PullRequest.SourceBranch'], 'feature'), contains(variables['System.PullRequest.SourceBranch'], 'bugfix'), contains(variables['System.PullRequest.SourceBranch'], 'ci'), contains(variables['System.PullRequest.SourceBranch'], 'hotfix')), succeeded())
      pool:
        vmImage: "ubuntu-latest"
      steps:
        - task: Cache@2
          inputs:
            key: 'npmV3 | "$(Agent.OS)" | package.json'
            restoreKeys: |
              npm | "$(Agent.OS)"
            path: "$(System.DefaultWorkingDirectory)/node_modules"
            cacheHitVar: CACHE_RESTORED
          displayName: Cache npm
        - script: |
            npm install --force
          condition: ne(variables.CACHE_RESTORED, 'true')
        - task: DownloadPipelineArtifact@2
          name: environment
          inputs:
            artifact: Environment
            targetPath: '$(System.DefaultWorkingDirectory)'
        - task: DownloadPipelineArtifact@2
          name: bundle
          inputs:
            artifact: bundle
            targetPath: '$(System.DefaultWorkingDirectory)'
        - script: |
            npm install pm2 -g
            npm install express --force
            pm2 start scripts/server.js
            docker run -u zap -p 8080:8080 -d softwaresecurityproject/zap-stable zap.sh -daemon -host 0.0.0.0 -port 8080 -config api.disablekey=true -config api.addrs.addr.name=.* -config api.addrs.addr.regex=true
            sleep 30
            mkdir test_results
            pip install beautifulsoup4
            pip install zaproxy
            python scripts/dast.py
          displayName: Dynamic Application Security Testing (DAST)
        - publish: $(System.DefaultWorkingDirectory)/test_results/report0.html # Assuming logs are in working directory
          artifact: dast_test_results
          condition: always()
        - script: |
            export AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID_MAIN}
            export AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY_MAIN}
            aws s3 sync living-documentation s3://$S3_BUCKET_LIVING_DOCUMENTATION/dast-admin/dev/ --acl public-read
            aws cloudfront create-invalidation --distribution-id $DISTRIBUTION_ID_DOCS --paths "/*"
          displayName: 'DAST Report documentation'
          condition: always()    
